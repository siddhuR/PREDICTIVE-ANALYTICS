#Boxplot
ggplot(data = df1, aes(x=factor(df1$rooms),
y=df1$price, fill=factor(rooms)))+geom_boxplot()
#Boxplot
ggplot(data = df1, aes(x=factor(df1$rooms),y=df1$price, fill=factor(rooms)))+
geom_boxplot()
#Boxplot
ggplot2(data = df1, aes(x=factor(df1$rooms),y=df1$price, fill=factor(rooms)))+
geom_boxplot()
library(ggplot2)
#Boxplot
ggplot2(data = df1, aes(x=factor(df1$rooms),y=df1$price, fill=factor(rooms)))+
geom_boxplot()
#Boxplot
ggplot(data = df1, aes(x=factor(df1$rooms),y=df1$price, fill=factor(rooms)))+
geom_boxplot()
#histogram
ggplot(data = df1, aes(x=price))+ geom_histogram()
df<-data("iris")
View(iris)
##See the structure
head(iris)
##Generate a random number that is 90% of the total number of rows in dataset.
ran<-sample(1:nrow(iris), 0.9*nrow(iris))
str(iris)
range(iris$Sepal.Length)
range(iris$Petal.Width)
View(iris)
##the normalization function is created.
nor<-function(x){ (x-min(x))/(max(x)-min(x)) }
iris_norm<-as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
summary(iris)
summary(iris_norm)
##extracting training set
iris_train <- iris_norm[ran,]
##extracting testing set
iris_test <- iris_norm[-ran,]
##extract 5th column of train dataset because it iwll be used as 'cl' argument in
##function.
iris_target_category<-iris[ran,5]
##extract 5th column if test dataset to measure the accuracy
iris_test_category<-iris[-ran,5]
##load the package class
install.packages("class")
library(class)
?knn
##run knn function
pr<-knn(iris_train,iris_test,cl=iris_target_category,k=10)
##Create confusion matrix
tab <- table(pr,iris_test_category)
##this function divides the correct predictions by total number of predictions
##that tells us how accurate the model is.
tab
accuracy<-function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
##Generate a random number that is 90% of the total number of rows in dataset.
ran<-sample(1:nrow(iris), 0.9*nrow(iris))
df<-data("iris")
##See the structure
head(iris)
##Generate a random number that is 90% of the total number of rows in dataset.
ran<-sample(1:nrow(iris), 0.9*nrow(iris))
str(iris)
range(iris$Sepal.Length)
range(iris$Petal.Width)
View(iris)
##the normalization function is created.
nor<-function(x){ (x-min(x))/(max(x)-min(x)) }
nor
iris_norm<-as.data.frame(lapply(iris[,c(1,2,3,4)], nor))
iris_norm
d<-iris[,c(1,2,3,4)]
d##extracting training set
##extracting training set
iris_train <- iris_norm[ran,]
##extracting testing set
iris_test <- iris_norm[-ran,]
##extract 5th column of train dataset because it iwll be used as 'cl' argument in
##function.
iris_target_category<-iris[ran,5]
iris_train
iris_test
iris_target_category
##extracting training set
iris_train <- iris_norm[ran,]
##extracting testing set
iris_test <- iris_norm[-ran,]
##extract 5th column of train dataset because it iwll be used as 'cl' argument in
##function.
iris_target_category<-iris[ran,5]
##extract 5th column if test dataset to measure the accuracy
iris_test_category<-iris[-ran,5]
##load the package class
install.packages("class")
install.packages("class")
library(class)
?knn
##run knn function
pr<-knn(iris_train,iris_test,cl=iris_target_category,k=10)
##Create confusion matrix
tab <- table(pr,iris_test_category)
##this function divides the correct predictions by total number of predictions
##that tells us how accurate the model is.
tab
accuracy<-function(x){sum(diag(x)/(sum(rowSums(x)))) * 100}
accuracy(tab)
##Create confusion matrix
tab <- table(pr,iris_test_category)
##this function divides the correct predictions by total number of predictions
##that tells us how accurate the model is.
tab
##APPLY MACHINE LEARNING MODEL ON DIAMOND DATASET
??diamond
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
##load data
View(diamonds)
df<-data(diamonds)
str(diamonds)
summary(diamonds)
##See the structure
head(diamonds)
#Generate a random numbers sample that is 90% of the total no. of rows of dataset.
ran<-sample(1:nrow(diamonds), 0.9*nrow(diamonds))
str(diamonds)
range(diamonds$carat)
range(diamonds$price)
##the normalization function is created.
nor<-function(x){ (x-min(x))/(max(x)-min(x)) }
dia_norm<-as.data.frame(lapply(diamonds[,c(1,5,6,7,8,9,10)], nor))
str(diamonds)
summary(diamonds)
summary(dia_norm)
##extracting training set
dia_train <- dia_norm[ran,]
##extracting testing set
dia_test <- dia_norm[-ran,]
##extract 2nd column of train dataset because it will be used as 'cl' argument in
##function.
##also convert ordered factor to normal factor
dia_target<-as.factor(diamonds[ran,2])
##extract 5th column if test dataset to measure the accuracy
dia_test<-as.factor(diamonds[-ran,2])
##extract 2nd column of train dataset because it will be used as 'cl' argument in
##function.
##also convert ordered factor to normal factor
dia_target<-as.factor(diamonds[ran,2])
str(diamonds)
df<-as.data(diamonds)
##extract 2nd column of train dataset because it will be used as 'cl' argument in
##function.
##also convert ordered factor to normal factor
dia_target<-diamonds[ran,2]
##extract 5th column if test dataset to measure the accuracy
dia_test<-diamonds[-ran,2]
##also convert ordered factor to normal factor
test_target<-as.factor(diamonds[-ran,2])
##also convert ordered factor to normal factor
test_target<- diamonds[-ran,2]
##load the package class
install.packages("class")
library(class)
?knn
##run knn function
pr<-knn(dia_train,dia_test,cl=dia_target,k=218)
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
df<- read.csv("Datasets/wisc_bc_data.csv")
View(df)
summary(df)
str(df)
##Generate random samples that is 90% of the total no. of rows of dataset.
ran<-sample(1:nrow(df),0.9*nrow(df))
##the normalization function is created.
nor<-function(x){ ((x-min(x) / max(x)-min(x))) }
df_norm<-as.data.frame(lapply(df[2:31], nor))
##Generate random samples that is 90% of the total no. of rows of dataset.
ran<-sample(1:nrow(df),0.9*nrow(df))
##the normalization function is created.
nor<-function(x){ (x-min(x))/(max(x)-min(x)) }
df_norm<-as.data.frame(lapply(df[2:31], nor))
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
wbcd<- read.csv("Datasets/wisc_bc_data.csv")
View(wbcd)
summary(wbcd)
str(wbcd)
wbcd <- wbcd[-1]
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B","M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis))*100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
normalize<-function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
wbcdd_test_labels<-wbcd[470:569, 1]
install.packages("class")
install.packages("class")
library(class)
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
wbcd<- read.csv("Datasets/wisc_bc_data.csv")
summary(wbcd)
str(wbcd)
wbcd <- wbcd[-1]
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B","M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis))*100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
normalize<-function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
wbcdd_test_labels<-wbcd[470:569, 1]
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
library(class)
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
install.packages("class")
install.packages("class")
library(class)
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
install.packages("gmodels")
library(gmodels)
CrossTable()
library(caret)
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
wbcd<- read.csv("Datasets/wisc_bc_data.csv")
View(wbcd)
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
wbcd<- read.csv("Datasets/wisc_bc_data.csv")
summary(wbcd)
str(wbcd)
wbcd <- wbcd[-1]
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B","M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis))*100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
normalize<-function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
wbcdd_test_labels<-wbcd[470:569, 1]
install.packages("class")
library(class)
wbcd_test_pred <- knn(tarin=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
wbcd_test_labels<-wbcd[470:569, 1]
install.packages("class")
library(class)
install.packages("class")
install.packages("class")
wbcd_test_pred <- knn(train=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
library(gmodels)
install.packages("class")
library(class)
wbcd_test_pred <- knn(train=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
install.packages("gmodels")
install.packages("gmodels")
CrossTable(x = wbcd_test_labels,y=wbcd_test_pred,
prop.chisq=FALSE)
aa<-table(wbcdd_test_labels,wbcd_test_pred)
library(caret)
confusionMatrix(aa)
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
wbcd<- read.csv("Datasets/wisc_bc_data.csv")
View(wbcd)
summary(wbcd)
str(wbcd)
wbcd <- wbcd[-1]
View(wbcd)
summary(wbcd)
str(wbcd)
wbcd <- wbcd[-1]
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B","M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis))*100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
normalize<-function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
wbcd<- read.csv("Datasets/wisc_bc_data.csv")
summary(wbcd)
str(wbcd)
wbcd <- wbcd[-1]
table(wbcd$diagnosis)
wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B","M"),
labels = c("Benign", "Malignant"))
round(prop.table(table(wbcd$diagnosis))*100, digits = 1)
summary(wbcd[c("radius_mean", "area_mean", "smoothness_mean")])
normalize<-function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
wbcd_n <- as.data.frame(lapply(wbcd[2:31], normalize))
summary(wbcd_n$area_mean)
wbcd_train<-wbcd_n[1:469, ]
wbcd_test<-wbcd_n[470:569, ]
wbcd_train_labels<-wbcd[1:469, 1]
wbcd_test_labels<-wbcd[470:569, 1]
library(class)
wbcd_test_pred <- knn(train=wbcd_train,test = wbcd_test,
cl = wbcd_train_labels, k=21)
library(gmodels)
CrossTable(x = wbcd_test_labels,y=wbcd_test_pred,
prop.chisq=FALSE)
aa<-table(wbcdd_test_labels,wbcd_test_pred)
library(caret)
confusionMatrix(aa)
getwd()
??chickmik
??chickwts
df <- chickwts
View(df)
summary(df)
str(df)
??diamonds
??chickwts
df <- chickwts
summary(df)
str(df)
View(df)
ggplot(data = df, aes(x=factor(df$feed),y=df$weight, fill=factor(feed)))+
geom_boxplot()
df <- ChickWeight
View(df)
summary(df)
str(df)
ggplot(data = df, aes(x=factor(df$feed),y=df$weight, fill=factor(feed)))+
geom_boxplot()
ggplot(data = df, aes(x=factor(df$Chick),y=df$weight, fill=factor(Chick)))+
geom_boxplot()
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
df <- read.csv("Datasets/student_data.csv")
View(df)
str(data)
getwd()
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes")
data <- read.csv("Datasets/student_data.csv")
View(data)
str(data)
library(naivebayes)
install.packages("naivebayes")
library(naivebayes)
library(naivebayes)
library(ggplot2)
library(psych)
install.packages("psych")
library(dplyr)
data <- read.csv("Datasets/student_data.csv")
View(data)
str(data)
summary(data)
??naivebayes
install.packages("e1071")
install.packages("naivebayes")
install.packages("psych")
library(naivebayes)
library(ggplot2)
library(psych)
library(dplyr)
install.packages("dplyr")
install.packages("dplyr")
install.packages("naivebayes")
library(dplyr)
data$rank <-as.factor(data$rank)
data$admit<- as.factor(data$admit)
str(data)
xtabs(~admit+rank,data=data)
pairs.panels(data[-1])
data %>% ggplot(aes(x=admit,y=gre,fill=admit)) + geom_boxplot()+ggtitle("Box Plot")
data$rank <-as.factor(data$rank)
data$admit<- as.factor(data$admit)
str(data)
xtabs(~admit+rank,data=data)
pairs.panels(data[-1])
data %>% ggplot(aes(x=admit,y=gre,fill=admit)) + geom_boxplot()+ggtitle("Box Plot")
data %>% ggplot(aes(x=gpa , fill=admit))+geom_boxplot() + ggtitle("BoxÂ Plot")
install.packages("rpart")
library(rpart)
library(rpart.plot)
View(iris)
set.seed(678)
s=sample(nrow(iris),100)
iris_train=iris[s, ]
iris_test=iris[-s,]
?rpart
iris_decision_tree_model = rpart(Species~., data=iris_train, method = "class")
iris_decision_tree_model
plot(iris_decision_tree_model)
text(iris_decision_tree_model)
?rpart.plot
rpart.plot(iris_decision_tree_model)
rpart.plot(iris_decision_tree_model)
rpart.plot(iris_decision_tree_model, type=4, extra=103)
iris_predict = predict(iris_decision_tree_model, iris_test, type="class")
iris_predict_table=table(iris_test[,5], iris_predict)
iris_predict_table
(iris_performance=sum(diag(iris_predict_table))/sum(iris_predict_table))*100
library(rpart)
library(rpart.plot)
View(Titanic)
#Setting the path of directory
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes/Datasets")
# Reading the dataset
df<-read.csv("TITANIC 1.csv")
View(df)
View(df)
summary(df)
#Setting the path of directory
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes/Datasets")
# Reading the dataset
df<-read.csv("TITANIC 1.csv")
View(df)
ggplot(data = df, aes(x=factor(df$Pclass),
y=df$Survived))+geom_boxplot()
# Boxplot
library(ggplot2)
ggplot(data = df, aes(x=factor(df$Pclass),
y=df$Survived))+geom_boxplot()
ggplot(data = df, aes(x=factor(df$Pclass),
y=df$Age))+geom_boxplot()
ggplot(data = df, aes(x=factor(df$Survived),
y=df$Age))+geom_boxplot()
library(dplyr)
library(rpart)
library(rpart.plot)
library(dplyr)
library(rpart)
library(rpart.plot)
set.seed(679)
View(Titanic)
head(Titanic)
summary(Titanic)
class(titanic)
class(Titanic)
str(Titanic)
is.na(Titanic)
Randomize<- sample(1,nrow(Titanic))
Randomize<- sample(1:nrow(Titanic))
Titanic<- Titanic[Randomize, ]
Titanic<- Titanic(Randomize, )
getwd()
library(dplyr)
library(rpart)
library(rpart.plot)
setwd("E:/Study/LPU/B.TECH/4th Year/7th Semester/INT234 - PREDICTIVE ANALYTICS/PREDICTIVE-ANALYTICS/R codes/Datasets")
data <- read.csv("TITANIC 1.csv")
View(data)
str(data)
summary(data)
data <- subset(data, select = c("PassengerId","Survived","Sex","Age","Fare","Pclass"))
str(data)
summary(data)
data$Age[is.na(data$Age)]<-mean(data$Age,na.rm = TRUE)
data$Fare[is.na(data$Fare)]<- mean(data$Fare,na.rm = TRUE)
#data$Survived <- as.factor(data$Survived)
data$Survived <- cut(data$Survived,2,levels=c(1,0), labels = c('Yes','No'))
data$Pclass <- cut(data$Pclass,3,levels=c(1,2,3),labels = c('Low','Medium','High'))
set.seed(678)
ran <- sample(1:nrow(data), 0.90 * nrow(data))
nor <- function(x) { (x - min(x)) / (max(x) - min(x)) }
cols<- c('PassengerId','Age','Fare')
data_norm <- data %>% mutate_at(cols,nor)
summary(data_norm)
train_data <-data_norm[ran,]
test_data <- data_norm[-ran,]
decision_tree_model = rpart(Survived~., data = train_data, method = "class")
plot(decision_tree_model)
rpart.plot(decision_tree_model)
data_predict = predict(decision_tree_model,test_data,type = "class")
data_prediction_table = table(test_data[,2],data_predict)
data_prediction_table
(data_performance = sum(diag(data_prediction_table))/sum(data_prediction_table))*100
